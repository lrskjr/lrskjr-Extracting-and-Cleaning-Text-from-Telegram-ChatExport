{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and Cleaning Text from Telegram ChatExport\n",
    "\n",
    "This notebook parses all html files in Telegram chat export , extracts message metadata and text, cleans the text for analysis, and saves outputs as:\n",
    "- A CSV file containing all parsed messages and fields\n",
    "- One cleaned TXT file per day (messages concatenated per date)\n",
    "\n",
    "The goal is a clean, analysis-ready corpus while preserving essential metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Working Directory\n",
    "\n",
    "Before running this notebook, you need to:\n",
    "\n",
    "1. **Download a chat history from Telegram:**\n",
    "   - Open Telegram and export the desired chat (Settings â†’ Chat Settings â†’ Export Chat History)\n",
    "   - Select HTML format (default format)\n",
    "\n",
    "2. **Save the export in a folder:**\n",
    "   - Create a folder in the same location as this notebook\n",
    "   - Name the folder with a relevant name (e.g., \"Alice_Weidel\" or \"Group_Chat_2024\")\n",
    "   - Copy all HTML files from the Telegram export into this folder\n",
    "\n",
    "3. **Enter the folder name when prompted:**\n",
    "   - In the next cell, the program will ask you to enter the folder name\n",
    "   - **Important:** Enter exactly the same name you gave the folder, as this name is used to locate the files and name the output files later in the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Jorge BuxadÃ©\n"
     ]
    }
   ],
   "source": [
    "# Iterate all files html files\n",
    "folder_name = input()\n",
    "\n",
    "folder = f'{folder_name}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Parse the Telegram Export\n",
    "\n",
    "- open and read the html file using UTF-8 encoding.\n",
    "- Parse the HTML with BeautifulSoup (bs).\n",
    "- We will later extract each message block (`div.message.default.clearfix`) to a tidy table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of html files in the chat export folder\n",
    "html_file_names = [i for i in os.listdir(folder) if i.endswith('.html')]\n",
    "\n",
    "def parse_into_bs(html_file):\n",
    "    \n",
    "    html_path = Path(rf'./{folder_name}/{html_file}')\n",
    "    with html_path.open(encoding=\"utf-8\") as f:\n",
    "        html = f.read()\n",
    "    \n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    return soup\n",
    "\n",
    "# from html to soup elements\n",
    "bs4_soup = [parse_into_bs(html_file) for html_file in html_file_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Parsing Messages\n",
    "\n",
    "This section:\n",
    "- Extracts message date/time from the `\"title\"` attribute (e.g., `02.09.2025 13:45:12 UTC+0`)\n",
    "- Reads the sender name (`div.from_name`)\n",
    "- Gets text content (`div.text`), preserving line breaks\n",
    "- Builds a pandas DataFrame with columns:\n",
    "  - `message_id`, `date`, `time`, `utc`, `from_name`, `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_title(body):\n",
    "    el = body.select_one(\"div.pull_right.date.details\")\n",
    "    title = el.get(\"title\", \"\").strip() if el else \"\"\n",
    "    date, time, utc = \"\", \"\", \"\"\n",
    "    if title:\n",
    "        parts = title.split(\" \", 2)\n",
    "        if len(parts) == 3:\n",
    "            date_raw, time, utc = parts\n",
    "            dparts = date_raw.split(\".\")\n",
    "            if len(dparts) == 3 and dparts[0].isdigit() and dparts[1].isdigit():\n",
    "                date = f\"{int(dparts[0])}.{int(dparts[1])}.{dparts[2]}\"\n",
    "            else:\n",
    "                date = date_raw\n",
    "        else:\n",
    "            date = title\n",
    "    return date, time, utc\n",
    "\n",
    "\n",
    "def get_from_name(body):\n",
    "    el = body.select_one(\"div.from_name\")\n",
    "    return el.get_text(strip=True) if el else \"\"\n",
    "\n",
    "\n",
    "def get_text(body):\n",
    "    el = body.select_one(\"div.text\")\n",
    "    if not el:\n",
    "        return \"\"\n",
    "    for br in el.find_all(\"br\"):\n",
    "        br.replace_with(\"\\n\")\n",
    "    return el.get_text(strip=True, separator=\"\\n\")\n",
    "\n",
    "\n",
    "def parse_message_div(msg):\n",
    "    body = msg.select_one(\"div.body\")\n",
    "    if body is None:\n",
    "        return {}\n",
    "    date, time, utc = get_datetime_title(body)\n",
    "    return {\n",
    "        \"message_id\": msg.get(\"id\", \"\"),\n",
    "        \"date\": date,\n",
    "        \"time\": time,\n",
    "        \"utc\": utc,\n",
    "        \"from_name\": get_from_name(body),\n",
    "        \"text\": get_text(body),\n",
    "    }\n",
    "\n",
    "def parse_all_messages_to_df(soup):\n",
    "    msgs = soup.select(\"div.message.default.clearfix\")\n",
    "    rows = [parse_message_div(m) for m in msgs]\n",
    "    rows = [r for r in rows if r]  # fjern tomme\n",
    "    return pd.DataFrame(rows, columns=[\n",
    "        \"message_id\",\n",
    "        \"date\",\n",
    "        \"time\",\n",
    "        \"utc\",\n",
    "        \"from_name\",\n",
    "        \"text\",\n",
    "    ])\n",
    "\n",
    "\n",
    "# Build DataFrame - parse the html data into a dataframe\n",
    "\n",
    "_df = [parse_all_messages_to_df(soup) for soup in bs4_soup]\n",
    "\n",
    "_df = pd.concat(_df).reset_index(drop=True)\n",
    "\n",
    "df = _df.sort_values('date', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the DataFrame and Clean Text\n",
    "\n",
    "- Construct the DataFrame from all parsed messages.\n",
    "- Clean the raw text:\n",
    "  - Replace newlines with spaces\n",
    "  - Remove URLs\n",
    "  - Collapse multiple spaces\n",
    "  - Keep word tokens only\n",
    "  - Lowercase\n",
    "- Add:\n",
    "  - `clean_text`: cleaned message text\n",
    "  - `word_count`: number of words in `clean_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text\n",
    "def clean_text(text):\n",
    "    _text = text.replace('\\n', ' ') # remove new lines\n",
    "    _text = re.sub(r'http.+\\b', ' ',  _text) # remove links\n",
    "    _text = re.sub(r'\\s+', ' ', _text) # remove multiple white space\n",
    "    _text = re.findall(r'\\b\\S+\\b', _text) # remove all signs but letters - return list\n",
    "    _text = ' '.join(_text) # join list to string \n",
    "    _text = _text.lower() # lower all letters\n",
    "    return _text.strip() # strip white spaces\n",
    "\n",
    "# Add new column with clean text\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Add the number of words in the clean text\n",
    "df['word_count'] = df['clean_text'].apply( lambda x : len(x.split())) \n",
    "\n",
    "# Filter data so only rows with word_count more than 10 are kept\n",
    "df = df.query('word_count > 9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>utc</th>\n",
       "      <th>from_name</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>message1850</td>\n",
       "      <td>1.1.2025</td>\n",
       "      <td>22:06:03</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Jorge BuxadÃ© ğŸ‡ªğŸ‡¸</td>\n",
       "      <td>#Programa1Minuto\\nTarjeta sanitaria Ãºnica, igu...</td>\n",
       "      <td>programa1minuto tarjeta sanitaria Ãºnica igual ...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>message1851</td>\n",
       "      <td>1.1.2025</td>\n",
       "      <td>22:07:11</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td></td>\n",
       "      <td>Frente a su odio y su blasfemia, amor, belleza...</td>\n",
       "      <td>frente a su odio y su blasfemia amor belleza y...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>message342</td>\n",
       "      <td>1.12.2020</td>\n",
       "      <td>22:23:11</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Jorge BuxadÃ© ğŸ‡ªğŸ‡¸</td>\n",
       "      <td>â€¼ï¸Frente al Gobierno que atenta contra el orde...</td>\n",
       "      <td>frente al gobierno que atenta contra el orden ...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>message1960</td>\n",
       "      <td>1.2.2025</td>\n",
       "      <td>20:55:24</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Jorge BuxadÃ© ğŸ‡ªğŸ‡¸</td>\n",
       "      <td>ğŸ”´ Bajo investigaciÃ³n la INJERENCIA DE LOS BURÃ“...</td>\n",
       "      <td>bajo investigaciÃ³n la injerencia de los burÃ³cr...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>message2045</td>\n",
       "      <td>1.3.2025</td>\n",
       "      <td>10:04:30</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Jorge BuxadÃ© ğŸ‡ªğŸ‡¸</td>\n",
       "      <td>Jornada ayer en el Pulgar con afectados por la...</td>\n",
       "      <td>jornada ayer en el pulgar con afectados por la...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>message2362</td>\n",
       "      <td>9.5.2025</td>\n",
       "      <td>13:22:33</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Jorge BuxadÃ© ğŸ‡ªğŸ‡¸</td>\n",
       "      <td>ğŸ”´ MÃS EXPROPIACIONES DE OLIVOS ğŸ”´\\nEn EspaÃ±a, e...</td>\n",
       "      <td>mÃ¡s expropiaciones de olivos en espaÃ±a el nego...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>message2562</td>\n",
       "      <td>9.7.2025</td>\n",
       "      <td>19:53:53</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Jorge BuxadÃ© ğŸ‡ªğŸ‡¸</td>\n",
       "      <td>Quiero dar la enhorabuena a Irene Montero por ...</td>\n",
       "      <td>quiero dar la enhorabuena a irene montero por ...</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>message2669</td>\n",
       "      <td>9.9.2025</td>\n",
       "      <td>09:07:04</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Jorge BuxadÃ© ğŸ‡ªğŸ‡¸</td>\n",
       "      <td>Mismo dÃ­a, tres teorÃ­as: que si el PP consider...</td>\n",
       "      <td>mismo dÃ­a tres teorÃ­as que si el pp considera ...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>message2672</td>\n",
       "      <td>9.9.2025</td>\n",
       "      <td>13:02:28</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Jorge BuxadÃ© ğŸ‡ªğŸ‡¸</td>\n",
       "      <td>ğŸ”´ El prÃ³ximo lunes, 15 de septiembre, en Tener...</td>\n",
       "      <td>el prÃ³ximo lunes 15 de septiembre en tenerife ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>message2673</td>\n",
       "      <td>9.9.2025</td>\n",
       "      <td>15:42:48</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Jorge BuxadÃ© ğŸ‡ªğŸ‡¸</td>\n",
       "      <td>Debate en Estrasburgo.\\nPSOE y PP se protegen ...</td>\n",
       "      <td>debate en estrasburgo psoe y pp se protegen mu...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>587 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       message_id       date      time        utc        from_name  \\\n",
       "1815  message1850   1.1.2025  22:06:03  UTC+01:00  Jorge BuxadÃ© ğŸ‡ªğŸ‡¸   \n",
       "1816  message1851   1.1.2025  22:07:11  UTC+01:00                    \n",
       "321    message342  1.12.2020  22:23:11  UTC+01:00  Jorge BuxadÃ© ğŸ‡ªğŸ‡¸   \n",
       "1925  message1960   1.2.2025  20:55:24  UTC+01:00  Jorge BuxadÃ© ğŸ‡ªğŸ‡¸   \n",
       "2010  message2045   1.3.2025  10:04:30  UTC+01:00  Jorge BuxadÃ© ğŸ‡ªğŸ‡¸   \n",
       "...           ...        ...       ...        ...              ...   \n",
       "2326  message2362   9.5.2025  13:22:33  UTC+01:00  Jorge BuxadÃ© ğŸ‡ªğŸ‡¸   \n",
       "2526  message2562   9.7.2025  19:53:53  UTC+01:00  Jorge BuxadÃ© ğŸ‡ªğŸ‡¸   \n",
       "2632  message2669   9.9.2025  09:07:04  UTC+01:00  Jorge BuxadÃ© ğŸ‡ªğŸ‡¸   \n",
       "2635  message2672   9.9.2025  13:02:28  UTC+01:00  Jorge BuxadÃ© ğŸ‡ªğŸ‡¸   \n",
       "2636  message2673   9.9.2025  15:42:48  UTC+01:00  Jorge BuxadÃ© ğŸ‡ªğŸ‡¸   \n",
       "\n",
       "                                                   text  \\\n",
       "1815  #Programa1Minuto\\nTarjeta sanitaria Ãºnica, igu...   \n",
       "1816  Frente a su odio y su blasfemia, amor, belleza...   \n",
       "321   â€¼ï¸Frente al Gobierno que atenta contra el orde...   \n",
       "1925  ğŸ”´ Bajo investigaciÃ³n la INJERENCIA DE LOS BURÃ“...   \n",
       "2010  Jornada ayer en el Pulgar con afectados por la...   \n",
       "...                                                 ...   \n",
       "2326  ğŸ”´ MÃS EXPROPIACIONES DE OLIVOS ğŸ”´\\nEn EspaÃ±a, e...   \n",
       "2526  Quiero dar la enhorabuena a Irene Montero por ...   \n",
       "2632  Mismo dÃ­a, tres teorÃ­as: que si el PP consider...   \n",
       "2635  ğŸ”´ El prÃ³ximo lunes, 15 de septiembre, en Tener...   \n",
       "2636  Debate en Estrasburgo.\\nPSOE y PP se protegen ...   \n",
       "\n",
       "                                             clean_text  word_count  \n",
       "1815  programa1minuto tarjeta sanitaria Ãºnica igual ...          38  \n",
       "1816  frente a su odio y su blasfemia amor belleza y...          19  \n",
       "321   frente al gobierno que atenta contra el orden ...          57  \n",
       "1925  bajo investigaciÃ³n la injerencia de los burÃ³cr...          35  \n",
       "2010  jornada ayer en el pulgar con afectados por la...          72  \n",
       "...                                                 ...         ...  \n",
       "2326  mÃ¡s expropiaciones de olivos en espaÃ±a el nego...          51  \n",
       "2526  quiero dar la enhorabuena a irene montero por ...         288  \n",
       "2632  mismo dÃ­a tres teorÃ­as que si el pp considera ...          99  \n",
       "2635  el prÃ³ximo lunes 15 de septiembre en tenerife ...          26  \n",
       "2636  debate en estrasburgo psoe y pp se protegen mu...          68  \n",
       "\n",
       "[587 rows x 8 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to CSV\n",
    "\n",
    "Export data to a CSV file for later analysis\n",
    "(e.g., in spreadsheets, Python, R, or Orange).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"csv_file\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "path = os.path.join(f\"./{out_dir}/{folder}_export.csv\")\n",
    "df.to_csv(path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export: Concatenate Cleaned Text by Day\n",
    "\n",
    "- Convert `date` to a proper datetime (day-first).\n",
    "- Group by day and concatenate all `clean_text` messages for that day.\n",
    "- Save one TXT per date into `txt_files_grouped_by_day/`.\n",
    "\n",
    "This is useful for daily-level analysis in tools like Voyant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 332 txt files in txt_files_grouped_by_day\n"
     ]
    }
   ],
   "source": [
    "_df = df.copy()\n",
    "_df['date'] = pd.to_datetime(_df['date'], dayfirst=True)\n",
    "df_grouped = _df.groupby('date')['clean_text'].apply( lambda x : ' '.join(x)).reset_index() \n",
    "df_grouped = df_grouped.rename(columns={'clean_text': 'concatenated_text'})\n",
    "\n",
    "out_dir = Path(\"txt_files_grouped_by_day\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def make_txt_filename(date_str):\n",
    "    date_str = str(date_str).strip().replace(\"-\", \"_\")[0:10]\n",
    "    if not date_str:\n",
    "        date_str = \"unknown_date\"\n",
    "    \n",
    "    return f'{date_str}.txt'\n",
    "\n",
    "\n",
    "written = 0\n",
    "for index, row in df_grouped.iterrows():\n",
    "    text = str(row['concatenated_text']).strip()\n",
    "    if not text:\n",
    "        continue\n",
    "    _fname = make_txt_filename(row.get((\"date\"), \"\"))\n",
    "    fname = folder + '_' + _fname\n",
    "    (out_dir / fname).write_text(text, encoding=\"utf-8\")\n",
    "    written += 1\n",
    "\n",
    "print(f\"Wrote {written} txt files in {out_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
