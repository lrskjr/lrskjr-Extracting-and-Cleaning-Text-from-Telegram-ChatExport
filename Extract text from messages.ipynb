{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and Cleaning Text from Telegram ChatExport\n",
    "\n",
    "This notebook parses all html files in Telegram chat export , extracts message metadata and text, cleans the text for analysis, and saves outputs as:\n",
    "- A CSV file containing all parsed messages and fields\n",
    "- One cleaned TXT file per day (messages concatenated per date)\n",
    "\n",
    "The goal is a clean, analysis-ready corpus while preserving essential metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Working Directory\n",
    "\n",
    "Before running this notebook, you need to:\n",
    "\n",
    "1. **Download a chat history from Telegram:**\n",
    "   - Open Telegram and export the desired chat (Settings â†’ Chat Settings â†’ Export Chat History)\n",
    "   - Select HTML format (default format)\n",
    "\n",
    "2. **Save the export in a folder:**\n",
    "   - Create a folder in the same location as this notebook\n",
    "   - Name the folder with a relevant name (e.g., \"Alice_Weidel\" or \"Group_Chat_2024\")\n",
    "   - Copy all HTML files from the Telegram export into this folder\n",
    "\n",
    "3. **Enter the folder name when prompted:**\n",
    "   - In the next cell, the program will ask you to enter the folder name\n",
    "   - **Important:** Enter exactly the same name you gave the folder, as this name is used to locate the files and name the output files later in the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Marine Le Pen\n"
     ]
    }
   ],
   "source": [
    "# Iterate all files html files\n",
    "folder_name = input()\n",
    "\n",
    "folder = f'{folder_name}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Parse the Telegram Export\n",
    "\n",
    "- open and read the html file using UTF-8 encoding.\n",
    "- Parse the HTML with BeautifulSoup (bs).\n",
    "- We will later extract each message block (`div.message.default.clearfix`) to a tidy table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of html files in the chat export folder\n",
    "html_file_names = [i for i in os.listdir(folder) if i.endswith('.html')]\n",
    "\n",
    "def parse_into_bs(html_file):\n",
    "    \n",
    "    html_path = Path(rf'./{folder_name}/{html_file}')\n",
    "    with html_path.open(encoding=\"utf-8\") as f:\n",
    "        html = f.read()\n",
    "    \n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    return soup\n",
    "\n",
    "# from html to soup elements\n",
    "bs4_soup = [parse_into_bs(html_file) for html_file in html_file_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Parsing Messages\n",
    "\n",
    "This section:\n",
    "- Extracts message date/time from the `\"title\"` attribute (e.g., `02.09.2025 13:45:12 UTC+0`)\n",
    "- Reads the sender name (`div.from_name`)\n",
    "- Gets text content (`div.text`), preserving line breaks\n",
    "- Builds a pandas DataFrame with columns:\n",
    "  - `message_id`, `date`, `time`, `utc`, `from_name`, `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_title(body):\n",
    "    el = body.select_one(\"div.pull_right.date.details\")\n",
    "    title = el.get(\"title\", \"\").strip() if el else \"\"\n",
    "    date, time, utc = \"\", \"\", \"\"\n",
    "    if title:\n",
    "        parts = title.split(\" \", 2)\n",
    "        if len(parts) == 3:\n",
    "            date_raw, time, utc = parts\n",
    "            dparts = date_raw.split(\".\")\n",
    "            if len(dparts) == 3 and dparts[0].isdigit() and dparts[1].isdigit():\n",
    "                date = f\"{int(dparts[0])}.{int(dparts[1])}.{dparts[2]}\"\n",
    "            else:\n",
    "                date = date_raw\n",
    "        else:\n",
    "            date = title\n",
    "    return date, time, utc\n",
    "\n",
    "\n",
    "def get_from_name(body):\n",
    "    el = body.select_one(\"div.from_name\")\n",
    "    return el.get_text(strip=True) if el else \"\"\n",
    "\n",
    "\n",
    "def get_text(body):\n",
    "    el = body.select_one(\"div.text\")\n",
    "    if not el:\n",
    "        return \"\"\n",
    "    for br in el.find_all(\"br\"):\n",
    "        br.replace_with(\"\\n\")\n",
    "    return el.get_text(strip=True, separator=\"\\n\")\n",
    "\n",
    "\n",
    "def parse_message_div(msg):\n",
    "    body = msg.select_one(\"div.body\")\n",
    "    if body is None:\n",
    "        return {}\n",
    "    date, time, utc = get_datetime_title(body)\n",
    "    return {\n",
    "        \"message_id\": msg.get(\"id\", \"\"),\n",
    "        \"date\": date,\n",
    "        \"time\": time,\n",
    "        \"utc\": utc,\n",
    "        \"from_name\": get_from_name(body),\n",
    "        \"text\": get_text(body),\n",
    "    }\n",
    "\n",
    "def parse_all_messages_to_df(soup):\n",
    "    msgs = soup.select(\"div.message.default.clearfix\")\n",
    "    rows = [parse_message_div(m) for m in msgs]\n",
    "    rows = [r for r in rows if r]  # fjern tomme\n",
    "    return pd.DataFrame(rows, columns=[\n",
    "        \"message_id\",\n",
    "        \"date\",\n",
    "        \"time\",\n",
    "        \"utc\",\n",
    "        \"from_name\",\n",
    "        \"text\",\n",
    "    ])\n",
    "\n",
    "\n",
    "# Build DataFrame - parse the html data into a dataframe\n",
    "\n",
    "_df = [parse_all_messages_to_df(soup) for soup in bs4_soup]\n",
    "\n",
    "_df = pd.concat(_df).reset_index(drop=True)\n",
    "\n",
    "df = _df.sort_values('date', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the DataFrame and Clean Text\n",
    "\n",
    "- Construct the DataFrame from all parsed messages.\n",
    "- Clean the raw text:\n",
    "  - Replace newlines with spaces\n",
    "  - Remove URLs\n",
    "  - Collapse multiple spaces\n",
    "  - Keep word tokens only\n",
    "  - Lowercase\n",
    "- Add:\n",
    "  - `clean_text`: cleaned message text\n",
    "  - `word_count`: number of words in `clean_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text\n",
    "def clean_text(text):\n",
    "    _text = text.replace('\\n', ' ') # remove new lines\n",
    "    _text = re.sub(r'http.+\\b', ' ',  _text) # remove links\n",
    "    _text = re.sub(r'\\s+', ' ', _text) # remove multiple white space\n",
    "    _text = re.findall(r'\\b\\S+\\b', _text) # remove all signs but letters - return list\n",
    "    _text = ' '.join(_text) # join list to string \n",
    "    _text = _text.lower() # lower all letters\n",
    "    return _text.strip() # strip white spaces\n",
    "\n",
    "# Add new column with clean text\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Add the number of words in the clean text\n",
    "df['word_count'] = df['clean_text'].apply( lambda x : len(x.split())) \n",
    "\n",
    "# Filter data so only rows with word_count more than 10 are kept\n",
    "df = df.query('word_count > 9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>utc</th>\n",
       "      <th>from_name</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>message258</td>\n",
       "      <td>1.10.2021</td>\n",
       "      <td>14:22:01</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Marine Le Pen</td>\n",
       "      <td>Depuis 27 ans, le mois d'octobre est l'occasio...</td>\n",
       "      <td>depuis 27 ans le mois d'octobre est l'occasion...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>message1226</td>\n",
       "      <td>1.10.2023</td>\n",
       "      <td>13:22:19</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Marine Le Pen</td>\n",
       "      <td>La dÃ©conjugalisation de lâ€™AAH, mesure que jâ€™ai...</td>\n",
       "      <td>la dÃ©conjugalisation de lâ€™aah mesure que jâ€™ai ...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>message1026</td>\n",
       "      <td>1.11.2022</td>\n",
       "      <td>12:01:39</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Marine Le Pen</td>\n",
       "      <td>Sous la pression de Bruxelles et dâ€™association...</td>\n",
       "      <td>sous la pression de bruxelles et dâ€™association...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>message1027</td>\n",
       "      <td>1.11.2022</td>\n",
       "      <td>19:27:14</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Marine Le Pen</td>\n",
       "      <td>En ce jour rÃ©servÃ© au souvenir de nos disparus...</td>\n",
       "      <td>en ce jour rÃ©servÃ© au souvenir de nos disparus...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>message1247</td>\n",
       "      <td>1.11.2023</td>\n",
       "      <td>18:34:25</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Marine Le Pen</td>\n",
       "      <td>Les disparus vivent dans nos cÅ“urs tant quâ€™il ...</td>\n",
       "      <td>les disparus vivent dans nos cÅ“urs tant quâ€™il ...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>message910</td>\n",
       "      <td>9.6.2022</td>\n",
       "      <td>13:44:42</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Marine Le Pen</td>\n",
       "      <td>ðŸŽ™ Je serai ce vendredi Ã  8h30 lâ€™invitÃ©e de RMC...</td>\n",
       "      <td>je serai ce vendredi Ã  8h30 lâ€™invitÃ©e de rmc e...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>message1169</td>\n",
       "      <td>9.6.2023</td>\n",
       "      <td>12:36:31</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Marine Le Pen</td>\n",
       "      <td>ðŸ“¹ Cette attaque d'Annecy, s'attaquer Ã  des bÃ©b...</td>\n",
       "      <td>cette attaque d'annecy s'attaquer Ã  des bÃ©bÃ©s ...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>message200</td>\n",
       "      <td>9.8.2021</td>\n",
       "      <td>19:55:34</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Marine Le Pen</td>\n",
       "      <td>ðŸ–‹ Â«Â Pass Sanitaire : les FranÃ§ais entrent en r...</td>\n",
       "      <td>pass sanitaire les franÃ§ais entrent en rÃ©siden...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>message199</td>\n",
       "      <td>9.8.2021</td>\n",
       "      <td>13:49:47</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Marine Le Pen</td>\n",
       "      <td>En France, on peut donc Ãªtre clandestin, incen...</td>\n",
       "      <td>en france on peut donc Ãªtre clandestin incendi...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>message963</td>\n",
       "      <td>9.9.2022</td>\n",
       "      <td>09:46:42</td>\n",
       "      <td>UTC+01:00</td>\n",
       "      <td>Marine Le Pen</td>\n",
       "      <td>On la pensait immortelle. La Reine Elizabeth I...</td>\n",
       "      <td>on la pensait immortelle la reine elizabeth ii...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1039 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       message_id       date      time        utc      from_name  \\\n",
       "228    message258  1.10.2021  14:22:01  UTC+01:00  Marine Le Pen   \n",
       "1134  message1226  1.10.2023  13:22:19  UTC+01:00  Marine Le Pen   \n",
       "943   message1026  1.11.2022  12:01:39  UTC+01:00  Marine Le Pen   \n",
       "944   message1027  1.11.2022  19:27:14  UTC+01:00  Marine Le Pen   \n",
       "1154  message1247  1.11.2023  18:34:25  UTC+01:00  Marine Le Pen   \n",
       "...           ...        ...       ...        ...            ...   \n",
       "831    message910   9.6.2022  13:44:42  UTC+01:00  Marine Le Pen   \n",
       "1080  message1169   9.6.2023  12:36:31  UTC+01:00  Marine Le Pen   \n",
       "176    message200   9.8.2021  19:55:34  UTC+01:00  Marine Le Pen   \n",
       "175    message199   9.8.2021  13:49:47  UTC+01:00  Marine Le Pen   \n",
       "881    message963   9.9.2022  09:46:42  UTC+01:00  Marine Le Pen   \n",
       "\n",
       "                                                   text  \\\n",
       "228   Depuis 27 ans, le mois d'octobre est l'occasio...   \n",
       "1134  La dÃ©conjugalisation de lâ€™AAH, mesure que jâ€™ai...   \n",
       "943   Sous la pression de Bruxelles et dâ€™association...   \n",
       "944   En ce jour rÃ©servÃ© au souvenir de nos disparus...   \n",
       "1154  Les disparus vivent dans nos cÅ“urs tant quâ€™il ...   \n",
       "...                                                 ...   \n",
       "831   ðŸŽ™ Je serai ce vendredi Ã  8h30 lâ€™invitÃ©e de RMC...   \n",
       "1080  ðŸ“¹ Cette attaque d'Annecy, s'attaquer Ã  des bÃ©b...   \n",
       "176   ðŸ–‹ Â«Â Pass Sanitaire : les FranÃ§ais entrent en r...   \n",
       "175   En France, on peut donc Ãªtre clandestin, incen...   \n",
       "881   On la pensait immortelle. La Reine Elizabeth I...   \n",
       "\n",
       "                                             clean_text  word_count  \n",
       "228   depuis 27 ans le mois d'octobre est l'occasion...          48  \n",
       "1134  la dÃ©conjugalisation de lâ€™aah mesure que jâ€™ai ...          63  \n",
       "943   sous la pression de bruxelles et dâ€™association...          33  \n",
       "944   en ce jour rÃ©servÃ© au souvenir de nos disparus...          23  \n",
       "1154  les disparus vivent dans nos cÅ“urs tant quâ€™il ...          37  \n",
       "...                                                 ...         ...  \n",
       "831   je serai ce vendredi Ã  8h30 lâ€™invitÃ©e de rmc e...          11  \n",
       "1080  cette attaque d'annecy s'attaquer Ã  des bÃ©bÃ©s ...          37  \n",
       "176   pass sanitaire les franÃ§ais entrent en rÃ©siden...          10  \n",
       "175   en france on peut donc Ãªtre clandestin incendi...          43  \n",
       "881   on la pensait immortelle la reine elizabeth ii...          37  \n",
       "\n",
       "[1039 rows x 8 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to CSV\n",
    "\n",
    "Export data to a CSV file for later analysis\n",
    "(e.g., in spreadsheets, Python, R, or Orange).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"csv_file\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "path = os.path.join(f\"./{out_dir}/{folder}_export.csv\")\n",
    "df.to_csv(path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export: Concatenate Cleaned Text by Day\n",
    "\n",
    "- Convert `date` to a proper datetime (day-first).\n",
    "- Group by day and concatenate all `clean_text` messages for that day.\n",
    "- Save one TXT per date into `txt_files_grouped_by_day/`.\n",
    "\n",
    "This is useful for daily-level analysis in tools like Voyant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 546 txt files in txt_files_grouped_by_day\n"
     ]
    }
   ],
   "source": [
    "_df = df.copy()\n",
    "_df['date'] = pd.to_datetime(_df['date'], dayfirst=True)\n",
    "df_grouped = _df.groupby('date')['clean_text'].apply( lambda x : ' '.join(x)).reset_index() \n",
    "df_grouped = df_grouped.rename(columns={'clean_text': 'concatenated_text'})\n",
    "\n",
    "out_dir = Path(\"txt_files_grouped_by_day\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def make_txt_filename(date_str):\n",
    "    date_str = str(date_str).strip().replace(\"-\", \"_\")[0:10]\n",
    "    if not date_str:\n",
    "        date_str = \"unknown_date\"\n",
    "    \n",
    "    return f'{date_str}.txt'\n",
    "\n",
    "\n",
    "written = 0\n",
    "for index, row in df_grouped.iterrows():\n",
    "    text = str(row['concatenated_text']).strip()\n",
    "    if not text:\n",
    "        continue\n",
    "    _fname = make_txt_filename(row.get((\"date\"), \"\"))\n",
    "    fname = folder + '_' + _fname\n",
    "    (out_dir / fname).write_text(text, encoding=\"utf-8\")\n",
    "    written += 1\n",
    "\n",
    "print(f\"Wrote {written} txt files in {out_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
